# Sign-Language-Detection
This model helps to recognize sign languageCommunication is an essential part of our daily lives, especially for deaf and dumb people who face difficulty in communicating with others. This paper introduces a method of using sign languages, i.e., to convert various hand gestures to appropriate text. The proposed method will help people with disabilities communicate or express their thoughts and opinions to others. The key objective of this neural network model is to bridge the communication gap and improve their quality of life by introducing novel techniques for sign character recognition. Here, a dataset of hand gestures is divided into training, validation, and testing sets to apply a convolutional neural network (CNN) to effectively recognize the different characters in the image. We also test it on random test data to ensure a reliable interpretation of the desired sign languages. The uniqueness of this model lies in the fact that we have used mixed pooling operation and the mish activation function to train the data more smoothly and robustly, improving the accuracy and precision in detecting sign character recognition. Index Termsâ€”Convolutional Neural Network, Mish activation function, Mixed pooling, Sign Character Recognition
